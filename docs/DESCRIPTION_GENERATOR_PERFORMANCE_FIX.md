# Исправление производительности AI генератора описаний

## Проблема
Генерация описаний была очень медленной и завершалась таймаутом:
- ❌ Блокировка event loop из-за синхронного вызова LLM API в async функции
- ❌ Использование медленной модели GPT-4o-mini
- ❌ Слишком длинный промпт
- ❌ Отсутствие индикатора прогресса для пользователя

## Исправления

### 1. Исправлена блокировка event loop
**Файл:** `services/recommender/main.py`
- Добавлена функция `call_openai_async()` которая выполняет синхронный вызов LLM в отдельном потоке через `run_in_executor()`
- Это предотвращает блокировку event loop FastAPI

### 2. Оптимизирована модель LLM
- Первичная модель: `google/gemini-flash-1.5-8b` (самая быстрая)
- Fallback: `openai/gpt-4o-mini` (если gemini-flash таймаут)
- Уменьшено `max_tokens` с 300 до 250 для ускорения

### 3. Упрощен промпт
- Сокращен системный промпт с ~20 строк до 3 строк
- Убраны избыточные инструкции
- Фокус на быстроту генерации

### 4. Добавлен индикатор прогресса
**Файл:** `src/admin/admin.js`
- Анимированный индикатор с точками "..."
- Сообщение о примерном времени ожидания (30-90 сек)
- Улучшены сообщения об ошибках

### 5. Оптимизированы таймауты
- Backend: 90 секунд для LLM запроса
- Frontend: 100 секунд для полного запроса
- HTTP клиент: 120 секунд

## Технические детали

### Async/await паттерн
```python
# До (блокировало event loop):
llm_response = openai_client.chat.completions.create(...)

# После (неблокирующий вызов):
llm_response = await call_openai_async(
    messages=messages,
    model="google/gemini-flash-1.5-8b",
    max_tokens=250
)
```

### Обработка event loop
```python
try:
    loop = asyncio.get_running_loop()
except RuntimeError:
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
```

## Ожидаемое время генерации

- **Gemini Flash**: 15-45 секунд
- **GPT-4o-mini (fallback)**: 30-60 секунд
- **Общее время**: 30-90 секунд (включая сетевые задержки)

## Проверка работы

1. Убедитесь, что все сервисы запущены:
   - Catalog (8000)
   - Recommender (8004)

2. Проверьте интернет-подключение (требуется для OpenRouter API)

3. Проверьте OPENROUTER_API_KEY в `config.env`

4. Откройте админ-панель и попробуйте сгенерировать описание

## Возможные проблемы

### Генерация всё ещё медленная
- Проверьте подключение к интернету
- Проверьте логи recommender service на наличие ошибок
- Убедитесь, что используется Gemini Flash (самая быстрая модель)

### Таймаут всё ещё возникает
- Убедитесь, что OpenRouter API доступен (может быть перегружен)
- Попробуйте позже
- Проверьте логи на наличие ошибок API

### Ошибка "event loop"
- Убедитесь, что используется последняя версия кода
- Перезапустите recommender service

## Улучшения в будущем

1. Кэширование промптов
2. Stream ответов от LLM для показа прогресса в реальном времени
3. Использование WebSocket для обновлений статуса
4. Предзагрузка часто используемых моделей

